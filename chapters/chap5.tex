\chapter{实验分析与讨论}
本章将详细描述本文所使用的实验数据，以及对实验结果的评价标准。本文在第四章中提出了TV-LibRec的第三方库推荐算法，本章将针对该算法，以及其各个部分的子算法（例如，基于文本的T-LibRec、基于视图的V-LibRec等），在数据集上进行相关实验，并与其他已有的著名推荐算法进行比较和讨论。


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%----------------------------------------     数据介绍     ---------------------------------------%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{数据介绍}
本文从最大的Android移动应用市场——Google Play上自动爬取了28,261个移动应用评分数据和程序包，并将其中描述数据缺失或下载不完整的移动应用删去，剩下23,398个移动应用，该数据集将作为本文的主要实验数据。本文所使用的实验数据包括移动应用元数据和程序包，下文将对这两类数据作详细说明。


\begin{table}
\centering
\caption{移动应用元数据类别及说明}
\begin{tabular}{|C{1.8in}|C{3.3in}|}
\hline
\textbf{元数据类别} & \textbf{数据描述} \\ \hline\hline
fileSize & 程序包的大小 \\ \hline
datePublished & 发布的时间 \\ \hline
name & 移动应用的名字 \\ \hline
author & 开发者名字 \\ \hline
url & 在Google Play市场上的页面链接 \\ \hline
price & 价格，免费或具体价格 \\ \hline
permission & 申请使用的权限 \\ \hline
contentRating & 内容评级，指适合的年龄段，例如“12+”表示内容适合12岁以上 \\ \hline
ids & 程序包的包名，唯一标识 \\ \hline
operatingSystems & 适用的Android操作系统版本 \\ \hline
softwareVersion & 当前程序包的版本号 \\ \hline
ratingValue & 用户评分值 \\ \hline
ratingCount & 评分数量 \\ \hline
genre & 在Google Play上所属的类别 \\ \hline
description & 描述内容 \\ \hline
reviews & 用户评论 \\ \hline
\end{tabular}
\end{table}

\subsection{元数据}
移动应用元数据（metadata）是指移动应用在Google Play市场上其内容页面所展示的基本信息。通常包括16类数据，如表5-1所示。

\begin{figure}
	\centering
	\includegraphics[width=5.8in]{figures/metadata}
	\caption{搜狗输入法在Google Play市场上的元数据。}
\end{figure}

图5-1显示的是从Google Play上爬取的搜狗输入法移动应用的元数据，其中第11行的用户评论过长，故折叠以便查看。本文主要使用的数据是第14行的评分值（\textsf{ratingValue}）和第17行的描述文字（\textsf{description}）。用户对移动应用的评分分为1至5五个等级，评分值则是对所有用户的评分平均之后的结果，其取值范围在$[1,5]$之间，如图5-1中搜狗输入法的评分值是4.31。描述文字是本文提出的基于文本的T-LibRec推荐算法的数据来源，其表征了移动应用在功能上的相似性。从图5-1中可以观察到，搜狗输入法的描述中除了英文单词以为，参杂了较多乱码（其实为中文字符的编码），因此本文在4.3.1节中对描述文本进行了数据清洗，保证在提取文本特征时只包含英文单词。所有从Google Play上爬取的移动应用元数据均以JSON（JavaScript Object Notation）格式存储在实验室服务器上，本文研究所需的评分值和描述文字都通过对JSON文本的分析抽取，其他未使用的元数据类别可以在未来的工作中进行扩充使用。


\subsection{程序包}
Android移动应用的程序包是以\textsf{APK}（Android Package Kit）的格式打包存储的。本文从Google Play市场上将研究所需的23,398个移动应用程序包都下载至实验室服务器，一共占249.86GB硬盘存储空间，其中最大的移动应用程序包为545.78MB，而最小的为20.42KB。本文对这2万多个移动应用，利用4.4.1节中提出的方法进行逆向工程。通常反编译一个移动应用所需时长为几分钟，为提高逆向工程效率，本文利用并行计算的方法，对数据集中的移动应用进行多线程反编译。最终，完成对数据集中所有移动应用反编译所消耗的计算时长大约为两周。

反编译后的移动应用以文件夹的形式存储，本文在4.4.1节中已详细介绍，在此不做赘述。第三方库在移动应用中的存储形式与移动应用本身相似，亦是以文件夹目录的形式存储。本文对移动应用根目录下的文件进行遍历，抽取并分析各个文件的路径。本文采用移动应用中最常使用的352个第三方库作为研究对象，对数据集中的移动应用进行查找，将使用了相应第三方库的移动应用以\textsf{[app\_id, lib\_id]}的形式进行记录，表示移动应用\textsf{app\_id}使用了第三方库\textsf{lib\_id}。本文所有实验都将在此数据集上进行验证和对比，若无特殊情况，将不再另作说明。



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%----------------------------------------     评价标准     ---------------------------------------%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{评价标准}
在对推荐系统算法进行评估时，通常使用准确率（Precision）\cite{yin2013app}和召回率（Recall）\cite{runeson2007detection}作为评价标准。本文同样采用此两种评价标准来衡量本文算法以及基准算法的表现。由于准确率和召回率有时会表现出不一致的实验结果，例如较小的准确率与较大的召回率会同时出现，因此本文亦引入F-measure\cite{rijsbergen1979information}评价标准来平衡准确率和召回率之间的关系。

给定一个长度为$L$的第三方库推荐列表，并根据推荐分数$\Omega$降序排列。定义推荐的第三方库被开发者采纳（即测试集中的移动应用使用了相应的第三方库）为命中（hit）。设$hit(L)$表示推荐列表$L$中被开发中采纳的数量，$T$表示测试集中所有开发者所使用的第三方库集合，则准确率和召回率可用如下公式表示：
\begin{equation}
precision = \frac{hit(L)}{|L|}
\end{equation}
\begin{equation}
recall = \frac{hit(L)}{|T|}
\end{equation}
其中，$|L|$表示第三方库推荐列表的数量，$|T|$表示所有实际被使用的第三方库的数量。准确率表征了在推荐的列表$L$中有多少比例的第三方库是实际被开发者所使用的，保证推荐列表中不包含过多不符合开发者需求的第三方库。召回率表征了推荐算法能够找到多少符合开发者需求的第三方库，保证推荐算法能够尽可能多地为开发者推荐第三方库。准确率和召回率是推荐过程中最需关注的两个方面。因此，本文引入F-measure评价标准来权衡他们间的结果关系，可以用以下公式表示：
\begin{equation}
F_\beta = (1+\beta^2) \cdot \frac{precision \cdot recall}{(\beta^2 \cdot precision) + recall},
\end{equation}
其中，参数$\beta$是权衡参数，用以权衡准确率与召回率之间的关系。在对开发者推荐第三方库的问题中，准确率和召回率都较重要，因此本文设定$\beta$参数为1，在所有实验评估中都采用该参数。

在后续实验中，本文采用准确率、召回率和F-measure这三个评价标准对实验结果进行评估。因为F-measure表征了准确率和召回率的综合结果，所以本文将在下文实验中重点分析和讨论F-measure的实验结果。



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%----------------------------------------     参数设定     ---------------------------------------%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{参数设定}
本文提出的TV-LibRec算法分别从文本和视图两个方面来计算移动应用间的相似性。在文本特征提取过程中，本文使用了doc2vec算法，将移动应用描述本文转化成文本向量。算法训练过程中涉及到5个参数，本文对这些参数进行实验分析，发现其对最终实验结果影响较小，因此将相关参数设定如下：文本向量的维度定为300维，以大小为10个单词的滑窗抽取单词语境，忽略语料库中数量少于10个的单词，对模型进行10次迭代，算法学习率为0.025。在聚类过程中，算法迭代次数的$\eta$参数和控制精度的$\varepsilon$参数同样对聚类结果影响较小，所有实验均能在20次迭代内达到收敛，且精度小于0.001，因而用以上数值设定参数。

除以上对实验结果影响较小的参数外，有5个较为重要的参数，
\begin{table}
\centering
\caption{TV-LibRec第三方库推荐算法重要参数说明}
\begin{tabular}{C{1in}C{1.2in}C{3.2in}}
\hline\hline
参数符号 & 算法部分 & 详细说明 \\
\hline\hline
$\mu$ & 相似性计算 & 文本与视图相似性间的比重 \\
$k$ & 移动应用聚类 & 聚类中移动应用簇的个数 \\
$\theta$ & 功能关系函数 & 相似性与评分值之间的比重 \\
$z$ & Top-z筛选 & 与开发者需求最相关的$z$个移动应用 \\
$\alpha$ & 第三方库推荐 & 控制第三方库推荐分数的变量 \\ 
\hline\hline
\end{tabular}
\end{table}
这些参数将影响TV-LibRec推荐算法的最终推荐效果，具体参数及其说明如表5-2所示。在参数分析过程中，本文固定实验数据的训练集和测试集的比例为9:1，即用90\%的实验数据作为已知的移动应用数据库，剩余的10\%作为开发者需要开发的移动应用。下文将对以上5个参数进行分析，并选择最优的结果作为本文算法的最终参数设定。

图5-2显示了5个参数分别对TV-LibRec算法推荐结果的影响。
\begin{figure}
	\centering
	\begin{subfigure}[b]{0.49\textwidth}
		\includegraphics[width=\textwidth]{figures/para_mu}
		\caption{文本与视图相似性间的比重参数$\mu$}
	\end{subfigure}
	\begin{subfigure}[b]{0.49\textwidth}
		\includegraphics[width=\textwidth]{figures/para_k}
		\caption{聚类中移动应用簇的个数$k$}
	\end{subfigure}
	\begin{subfigure}[b]{0.49\textwidth}
		\includegraphics[width=\textwidth]{figures/para_theta}
		\caption{相似性与评分值之间的比重参数$\theta$}
	\end{subfigure}
	\begin{subfigure}[b]{0.49\textwidth}
		\includegraphics[width=\textwidth]{figures/para_z}
		\caption{Top-z筛选中的参数$z$}
	\end{subfigure}
	\begin{subfigure}[b]{0.49\textwidth}
		\includegraphics[width=\textwidth]{figures/para_alpha}
		\caption{第三方库推荐分数控制参数$\alpha$}
	\end{subfigure}
	\caption{参数对TV-LibRec算法的影响。}
\end{figure}
为方便查看，本文将准确率、召回率和F-measure的结果值放在同一张折线图中表示。其中蓝色框折线图表示准确率，绿色圈折线图表示召回率，红色三角折线图表示F-measure。因为本文以F-measure为主要评价标准，因此将着重分析F-measure结果的变化情况。

从图5-2(a)中可以观察到，参数$\mu$从0.1增加到0.4的过程中，三个评价标准均单调递增。之后随着参数$\mu$的继续增加，仅准确率这一评价标准有略微提高，其他两项结果均下降，尤其是召回率。因此，当$\mu=0.4$时，F-measure结果达到最优值。参数$\mu$表示的是文本和视图相似性间的比重关系，文本相似性一定程度上能够表征移动应用间的相似性，但由于其缺少移动应用代码层的特征信息，因此不能涵盖移动应用的所有信息，视图相似性也具有类似特点。所以，仅利用其中一项相似性计算方法，不能获得较好的结果，如图5-2(a)中参数$\mu$在两侧结果较差。本文设定参数$\mu$为0.4，并在之后的实验中均使用该设定。

图5-2(b)显示了聚类算法中的簇的个数对第三方库推荐的影响。通过观察可以发现，准确率在不同聚类情况下变化不明显，而召回率有一定的波动，特别是簇的个数在40之前，结果随着簇个数的增加而提高，之后又下降。以F-measure作为分析对象，可以认为推荐结果在$k=40$时达到最优。聚类中簇的个数影响了可选相似应用的数量，如果簇越多，则意味着每个簇的移动应用个数将相应减少，可能无法找到足够多与开发者需求相近的移动应用；若簇越少，则每个簇中包含了相似性相对较低的移动应用，进而会影响最终的推荐效果。因此，本文设定$k=40$作为聚类的参数。

在为开发者选择参考移动应用时，若只考虑移动应用间的相似性，则会引入质量较差的移动应用，进而导致推荐的第三方库质量无法保证。因此，本文在相似移动应用筛选中加入了参数$\theta$，以权衡移动应用功能关系和评分情况，如图5-2(c)所示。在参数$\theta$变化过程中，准确率的波动较小，一直处于0.6-0.65之间，而召回率则随着$\theta$的增加明显增长，说明移动应用间的相似性确实能够有效地表征开发者的需求。从F-measure结果来看，当$\theta=0.7$时到达了最高点，说明评分在第三方库推荐中虽然不是主要影响因素，但着实会左右开发者对第三方库的选择。因此，本文选用0.7作为参数$\theta$的最优值。

Top-z筛选的目的是为了能够选择最符合开发者需求的相关移动应用。直观而言，选择更多的移动应用能够获得更好的效果，但事实未然。本文通过研究参数$z$来分析筛选过程中移动应用数量对实验结果的影响。如图5-2(d)所示，整体而言，三个评价标准的结果均随着$z$的增加而提高，但是仔细观察可以发现，在$z=25$处有个小转折，特别是召回率有显著下降的趋势。因为，当参考过多的移动应用时，容易引入使用量较少、质量较差的第三方库，而此类第三方库一般不会被开发者采纳。所以，选择适量的参考移动应用显得尤为重要。本文以$z=25$作为最终选择。

图5-2(e)所显示的是对候选列表中第三方库进行筛选的分析。参数$\alpha$用以对公式(4-21)计算所得的推荐分数$\Omega$进行控制。第三方库的推荐分数$\Omega$表征了第三方库对开发者而言的重要性，越重要的第三方库越可能被开发者采纳。因此，本文引入参数$\alpha$作为阈值筛选，将重要性较低的第三方库剔除。从图5-2(e)中可以观察到，随着阈值的增大，准确率逐渐变高。因为不断提高推荐阈值，意味着筛选出来的第三方库被开发者采纳的可能性越高。然而，召回率会随之下降，由于较多第三方库被排除在外，导致一些开发者可能会采纳的第三方库也不在推荐列表中。可以发现，当$\alpha=0.2$时，F-measure得到了最好的结果，因此该值作为算法最佳参数。

通过对5个重要参数的实验分析，本文找到了最佳的参数设定：$\mu=0.4$、$k=40$、$\theta=0.7$、$z=25$、$\alpha=0.2$。在5.4节与其他算法比较时，将使用以上参数设定。



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%----------------------------------------     实验对比     ---------------------------------------%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{实验对比}
本文提出的TV-LibRec算法充分利用了移动应用间的文本和视图相似性，并以此将功能相近的移动应用聚为一类，进而为开发者推荐第三方库。为了评估本文提出的算法的推荐能力，本文将其与已有的其他著名推荐算法进行比较，从而证明本文提出的算法的有效性。所有对比实验均在本文收集的23,398个移动应用的数据集上进行测试。本文将实验数据集分为两个部分：训练集和测试集，并使测试集占整个数据集的百分比从5\%增加至40\%（步长为5\%），从而比较不同算法在不同比例的测试集下的表现。


\subsection{基准算法}
本文提出的TV-LibRec第三方库推荐算法利用了文本和视图两方面信息，且利用聚类算法将相似移动应用进行聚类，因此在实验比较过程中，将分别对以上算法部分进行实验分析，并与已有的其他著名推荐算法进行比较。具体实验比较将分为以下三分部分：
\begin{itemize}
\item
比较文本与视图相似性。本文提出的TV-LibRec算法中利用了移动应用的文本和视图两个层面的信息，因此本章将分别对这两种相似性进行分析和实验比较。特别的，在文本相似性计算过程中，本文提出了两种计算方法：皮尔森相关系数和余弦相似度，因此也将对这两种相似度计算结果进行比对。

\item
比较不同聚类算法。本文在4.5节中分析和讨论了k-means和单连接的层次聚类算法在移动应用聚类中的优缺点，并提出了本文的k-min聚类算法。为证明聚类算法对第三方库推荐的有效性，本文将使用k-min聚类算法的TV-LibRec，分别与使用k-means、单连接的层次聚类和随机聚类的基准算法进行比较。

\item
与著名推荐算法进行比较。现有推荐算法通常将用户和项目构建成一个用户-项目矩阵（User-Item Matrix），然后对矩阵中的数据进行分析和学习，从而为用户推荐合适的项目。在本文研究问题中，用户为开发者，项目为第三方库。由Salakhutdinov等\cite{salakhutdinov2011probabilistic}提出的概率矩阵分解（PMF: Probabilistic Matrix Factorization）模型，在传统矩阵分解方法的基础上，加入了先验概率，从而能够更准确地为用户推荐项目\cite{liu2013bayesian}。非负矩阵分解（NMF: Non-Negative Matrix Factorization）算法则在传统矩阵分解方法基础上，引入了矩阵中各值非负的规则，从而能够获得更好的推荐效果\cite{luo2014efficient}。此外，本文还将与基于项目的协同过滤算法进行比较（IPCC）\cite{yang2014survey}。
\end{itemize}


\subsection{对比结果与分析}
本文从文本和视图两个层面对移动应用进行相似性计算，其中在文本相似性计算过程中分别使用了皮尔森相关系数和余弦相似度，因此对以上三种相似性计算进行比较。如图5-3所示，其中T-PCC-LibRec表示使用皮尔森相关系数对文本进行相似性计算的第三方库推荐算法，
\begin{figure}
	\centering
	\begin{subfigure}[b]{0.495\textwidth}
		\includegraphics[width=\textwidth]{figures/feature_comp_p}
		\caption{准确率实验结果}
	\end{subfigure}
	\begin{subfigure}[b]{0.495\textwidth}
		\includegraphics[width=\textwidth]{figures/feature_comp_r}
		\caption{召回率实验结果}
	\end{subfigure}
	\begin{subfigure}[b]{0.5\textwidth}
		\includegraphics[width=\textwidth]{figures/feature_comp_f}
		\caption{F-measure实验结果}
	\end{subfigure}
	\caption{不同的移动应用特征与相似度计算方法比较。}
\end{figure}
T-COS-LibRec表示使用余弦相似度对文本进行相似性计算的算法，V-LibRec为利用视图相似性的推荐算法，TV-LibRec为同时利用了文本和视图相似性的算法，且使用余弦相似度计算文本间相似性。从图5-3(a)中观察可知，利用移动应用视图层面的相似性能够更准确的为开发者推荐相关第三方库（TV-LibRec和V-LibRec的准确率结果大于T-LibRec），从而说明移动应用代码层相较于描述，包含更多功能信息，更能表征移动应用特征信息。图5-3(b)和5-3(c)同样说明了此问题，证明视图特征在第三方库推荐中优于文本特征。特别的，在图5-3(b)中，V-LibRec的召回率高于TV-LibRec，从侧面说明文本特征反而影响了推荐效果。但综合准确率和召回率，TV-LibRec相比于仅利用文本或视图的推荐算法，具有更好的推荐效果。此外，使用皮尔森相关系数与使用余弦相似度在准确率和召回率上各有优势，从F-measure看，两者的差别并不明显，但余弦相似度在测试集较小的情况下表现优于皮尔森相关系数，现实中更符合这种情况，因此本文选用余弦相似度作为本文相似性计算方法。

本文对相似移动应用进行聚类，以方便搜寻符合开发者需求的相似移动应用。著名的k-means聚类算法和单连接的层次聚类算法能够解决相似移动应用聚类的问题，但其具有一定局限性，因此本文提出了一个更符合移动应用聚类的聚类算法。
\begin{figure}
	\centering
	\begin{subfigure}[b]{0.495\textwidth}
		\includegraphics[width=\textwidth]{figures/cluster_comp_p}
		\caption{准确率实验结果}
	\end{subfigure}
	\begin{subfigure}[b]{0.495\textwidth}
		\includegraphics[width=\textwidth]{figures/cluster_comp_r}
		\caption{召回率实验结果}
	\end{subfigure}
	\begin{subfigure}[b]{0.5\textwidth}
		\includegraphics[width=\textwidth]{figures/cluster_comp_f}
		\caption{F-measure实验结果}
	\end{subfigure}
	\caption{不同聚类算法比较。}
\end{figure}
\begin{table*}
\small
\setlength{\tabcolsep}{3.8pt}
\centering
\caption{不同推荐算法的F-measure结果比较}
\begin{tabular}{c c c c c c c c c}
\hline\hline
Test data & 5\% & 10\% & 15\% & 20\% & 25\% & 30\% & 35\% & 40\% \\
\hline
IPCC & 0.061158 & 0.061595 & 0.060085 & 0.059930 & 0.059815 & 0.059352 & 0.059180 & 0.059747 \\

NMF & 0.279595 & 0.272422 & 0.274156 & 0.282729 & 0.293396 & 0.296581 & 0.295678 & 0.296248 \\

PMF & 0.279615 & 0.272791 & 0.281162 & 0.290922 & 0.296766 & 0.296029 & 0.295091 & 0.296159  \\

Random & 0.654009 & 0.655032 & 0.656605 & 0.651721 & 0.652992 & 0.652588 & 0.652447 & 0.656236 \\

TV-LibRec & 0.705193 & 0.696188 & 0.690988 & 0.691516 & 0.688176 & 0.698498 & 0.693270 & 0.686949 \\
\hline\hline
\end{tabular}
\end{table*}
为了验证本文提出的聚类算法的有效性，本文分别与使用k-means聚类算法（K-means）、单连接的层次聚类算法（Single）和不使用任何聚类算法（Random）的推荐方法进行比较，且此三种推荐算法仅是在TV-LibRec的基础上换掉相应的聚类算法，因此仍然利用了移动应用的文本和视图特征。从图5-4(a)中可以观察到，k-means的准确率极为不稳定，大部分结果都低于TV-LibRec，但是有两个实验结果高于TV-LibRec，三个实验结果甚至低于Random。Single的准确率也同样不稳定，有部分结果高于TV-LibRec，但也有部分低于TV-LibRec和k-means。图5-4(b)中的召回率结果相对较为稳定，TV-LibRec要优于其他三种方法，使用k-means聚类的方法召回率不如Random和Single。从综合结果F-measure来看，如图5-4(c)所示，TV-LibRec具有最好的推荐效果，而k-means居其后，单连接的层次聚类算法次之，Random最差。从实验结果可以发现，使用k-means和单连接的层次聚类算法可以达到一定的聚类效果，但正如本文在4.5节中所分析的，这两种方法可能会出现某些非最优的聚类情况，因此在实验中的表现不稳定，且整体效果差于本文提出的k-min聚类算法。

最后，本文与著名的推荐算法IPCC、NMF、PMF进行实验比较，具体实验结果如表5-3所示。从表5-3中观察可知，其中未使用移动应用间的相似性的推荐算法（IPCC、NMF、PMF）结果表现都较差，特别是仅利用了移动应用所使用的第三方库间的相似关系的IPCC。NMF和PMF推荐算法充分利用了整个用户-项目矩阵（移动应用与第三方库构成的矩阵）的全局信息，因此能够更全面的分析开发者所需的功能需求。但由于没有移动应用本身的功能信息，导致这些推荐算法无法有效地从第三方库使用情况中获取功能相关的特征，因此无法给出较好的推荐效果。与之不同的Random方法，虽然未对相似移动应用进行聚类，但是其利用了移动应用在文本和视图层面的特征信息，能够掌握开发者的功能需求，从其他相似移动应用中抽取相应的第三方库，所以其推荐效果会优于前三种方法。TV-LibRec则充分利用了移动应用间的相似性，并对其进行了聚类操作，使得与开发者需求相符的移动应用均在同一簇中，从而能够更好地为开发者推荐所需的第三方库。

根据以上三组对比实验分析可得，本文提出的基于文本和视图的TV-LibRec第三方库推荐算法能够有效地为移动应用开发者推荐第三方库，且优于现有的著名推荐算法，从而说明本文提出的文本和视图特征能够有效地表征移动应用的功能信息和开发者的需求。



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%----------------------------------------     本章小结     ---------------------------------------%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{本章小结}
本章详细介绍了本文所使用的实验数据。该数据是由从Google Play上爬取的23,398个移动应用所组成的，其中包括移动应用的元数据和程序包。元数据一共包括了16类数据，本文在文本特征提取中使用了其中的描述，在第三方库推荐的过程中使用了用户评分，以权衡第三方库的功能和质量关系。对移动应用程序包的分析在本文4.4.1节中做了详细分析和解释，因此本章较为简略地说明了反编译后的数据信息。

为了准确衡量实验结果，本章给出了三种评价标准，分别是准确率、召回率和F-measure。这三种评价标准在推荐系统算法评估中被广泛使用，本文使用同样的评价标准来衡量推荐效果。由于准确率和召回率间常出现矛盾的结论，因此本文着重考虑权衡两者的F-measure评价标准。

对于本文提出的TV-LibRec推荐算法，有5个重要的参数会影响最终的推荐效果。因此，本章对这5个重要参数进行实验分析。在本文的实验数据集上以训练集与测试集9:1的分割方式进行实验，本章确定了每个重要参数在实际实验结果中的最优值，从而作为本文推荐算法的参数设定。

最后，本章将本文提出的TV-LibRec第三方库推荐算法与各基准算法进行比较，从而验证本文算法的有效性。本章一共分成三个部分来研究分析TV-LibRec算法的实验效果：比较TV-LibRec算法中文本和视图特征的有效性；比较TV-LibRec算法中k-min聚类算法的有效性；与其他现有的著名推荐算法进行比较。通过实验分析发现，视图特征相比文本特征，能够更有效地表征移动应用的功能信息，得到了更好的第三方库推荐效果。在文本相似性计算过程中，皮尔森相关系数与余弦相似度两种计算方法并无较大差异，但余弦相似度在较小测试集情况下有较优的表现，符合真实场景，因此作为TV-LibRec中的文本相似性计算方法。本章亦通过实验证明了本文提出的k-min聚类算法在移动应用聚类问题上，比k-means算法和单连接的层次聚类算法有更好更稳定的表现，与本文在4.5节中的分析相符。在与其他著名推荐算法的比较中，TV-LibRec算法表现出了较好的实验结果，且说明了本文提出的移动应用相似性在第三方库推荐中具有重要的作用。